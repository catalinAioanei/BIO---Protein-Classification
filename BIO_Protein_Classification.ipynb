{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BIO - Protein Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hdz-MS2bCy0y",
        "JfplQ7cG_Vjq",
        "ZQAUvQLgJftw",
        "6YLgHnRz7EIZ"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEVaQR0Y9xmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Conv1d, Conv2d, Linear\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.special import expit\n",
        "from tqdm import tqdm\n",
        "import io\n",
        "import re\n",
        "from google.colab import files\n",
        "import math\n",
        "import random\n",
        "import gc\n",
        "import zipfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPFo5oj09416",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import spacy\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from nltk import agreement\n",
        "from nltk.stem import *\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords\n",
        "from scipy.stats import spearmanr\n",
        "from torch.nn import CosineSimilarity\n",
        "from torch.nn import functional\n",
        "from collections import Counter\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX8QYLkS98C6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%shell\n",
        "pip install allennlp;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjNee-um998p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import Iterator, List, Dict, Optional\n",
        "from allennlp.data import Instance\n",
        "from allennlp.data.fields import TextField, SequenceLabelField, LabelField, ArrayField\n",
        "from allennlp.data.dataset_readers import DatasetReader\n",
        "from allennlp.common.file_utils import cached_path\n",
        "from allennlp.common.util import START_SYMBOL, END_SYMBOL\n",
        "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer, PretrainedBertIndexer\n",
        "from allennlp.data.token_indexers.elmo_indexer import ELMoTokenCharactersIndexer\n",
        "from allennlp.data.tokenizers import Token\n",
        "from allennlp.data.vocabulary import Vocabulary\n",
        "from allennlp.nn.activations import Activation\n",
        "from allennlp.models import Model, BiattentiveClassificationNetwork\n",
        "from allennlp.modules.attention import LinearAttention, BilinearAttention, DotProductAttention\n",
        "from allennlp.modules.feedforward import FeedForward\n",
        "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
        "from allennlp.modules.token_embedders.bert_token_embedder import PretrainedBertEmbedder\n",
        "from allennlp.models.encoder_decoders.simple_seq2seq import SimpleSeq2Seq\n",
        "from allennlp.modules.token_embedders import Embedding, ElmoTokenEmbedder\n",
        "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper, StackedSelfAttentionEncoder\n",
        "from allennlp.modules.seq2vec_encoders import Seq2VecEncoder, PytorchSeq2VecWrapper, CnnEncoder\n",
        "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n",
        "from allennlp.training.metrics import CategoricalAccuracy\n",
        "from allennlp.nn.activations import Activation\n",
        "from allennlp.data.iterators import BucketIterator, BasicIterator, DataIterator\n",
        "from allennlp.training.trainer import Trainer\n",
        "from allennlp.predictors import SimpleSeq2SeqPredictor\n",
        "from allennlp.predictors.seq2seq import Seq2SeqPredictor\n",
        "from allennlp.nn import util as nn_util\n",
        "from allennlp.predictors import SentenceTaggerPredictor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y92fUgk69_xD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(1);\n",
        "\n",
        "CUDA_DEVICE = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmOaIQ5N-Asq",
        "colab_type": "text"
      },
      "source": [
        "# Data Loading and Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D6CMQCy-C5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bio_path = \"/content/BIO---Protein-Classification/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC07u4NxWBC8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "cccb7e40-38d2-4240-8b88-a5496c5ad53c"
      },
      "source": [
        "!git clone https://github.com/catalinAioanei/BIO---Protein-Classification"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'BIO---Protein-Classification'...\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects:  14% (1/7)\u001b[K\rremote: Counting objects:  28% (2/7)\u001b[K\rremote: Counting objects:  42% (3/7)\u001b[K\rremote: Counting objects:  57% (4/7)\u001b[K\rremote: Counting objects:  71% (5/7)\u001b[K\rremote: Counting objects:  85% (6/7)\u001b[K\rremote: Counting objects: 100% (7/7)\u001b[K\rremote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 7 (delta 0), reused 7 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (7/7), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_QBOA_3uZ5r",
        "colab_type": "text"
      },
      "source": [
        "#### Preparing the annotated proteins files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWRXVnYZs01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nucleus_proteins = open(bio_path + \"nucleus.fasta.txt\", 'r')\n",
        "nucleus_proteins = nucleus_proteins.read()\n",
        "nucleus_proteins = nucleus_proteins.split(\">sp\")[1:]\n",
        "nucleus_proteins = {\"Header\":[protein.split(\"\\n\", 1)[0] for protein in nucleus_proteins], \n",
        "                \"Sequence\": [protein.split(\"\\n\",1)[1].replace(\"\\n\", \"\") for protein in nucleus_proteins], \n",
        "                \"Label\": \"nucleus\"}\n",
        "nucleus_proteins = pd.DataFrame(nucleus_proteins)\n",
        "\n",
        "\n",
        "cito_proteins = open(bio_path + \"cito.fasta.txt\", 'r')\n",
        "cito_proteins = cito_proteins.read()\n",
        "cito_proteins = cito_proteins.split(\">sp\")[1:]\n",
        "cito_proteins = {\"Header\":[protein.split(\"\\n\", 1)[0] for protein in cito_proteins], \n",
        "                \"Sequence\": [protein.split(\"\\n\",1)[1].replace(\"\\n\", \"\") for protein in cito_proteins], \n",
        "                \"Label\": \"cito\"}\n",
        "cito_proteins = pd.DataFrame(cito_proteins)\n",
        "\n",
        "\n",
        "mito_proteins = open(bio_path + \"mito.fasta.txt\", 'r')\n",
        "mito_proteins = mito_proteins.read()\n",
        "mito_proteins = mito_proteins.split(\">sp\")[1:]\n",
        "mito_proteins = {\"Header\":[protein.split(\"\\n\", 1)[0] for protein in mito_proteins], \n",
        "                \"Sequence\": [protein.split(\"\\n\",1)[1].replace(\"\\n\", \"\") for protein in mito_proteins], \n",
        "                \"Label\": \"mito\"}\n",
        "mito_proteins = pd.DataFrame(mito_proteins)\n",
        "\n",
        "\n",
        "secreted_proteins = open(bio_path + \"secreted.fasta.txt\", 'r')\n",
        "secreted_proteins = secreted_proteins.read()\n",
        "secreted_proteins = secreted_proteins.split(\">sp\")[1:]\n",
        "secreted_proteins = {\"Header\":[protein.split(\"\\n\", 1)[0] for protein in secreted_proteins], \n",
        "                \"Sequence\": [protein.split(\"\\n\",1)[1].replace(\"\\n\", \"\") for protein in secreted_proteins], \n",
        "                \"Label\": \"secreted\"}\n",
        "secreted_proteins = pd.DataFrame(secreted_proteins)\n",
        "                "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKHLY-oyuimf",
        "colab_type": "text"
      },
      "source": [
        "##### Preparing the blind test proteins file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eizk2nvpquEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "blind_test = open(bio_path + \"blind_test.fasta.txt\", 'r')\n",
        "blind_test = blind_test.read()\n",
        "blind_test = blind_test.split(\">\")[1:]\n",
        "\n",
        "blind_test = {\"Header\":[protein.split(\"\\n\", 1)[0] for protein in blind_test], \n",
        "              \"Sequence\": [protein.split(\"\\n\",1)[1].replace(\"\\n\", \"\") for protein in blind_test],\n",
        "              \"Label\": \"mito\"} \n",
        "# we put mito label just as a hack, so that the predictor will stop complayining\n",
        "# ignore the label field for the blind_test dataframe and just focus on the prediction column\n",
        "blind_test = pd.DataFrame(blind_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tRvYA67uqIM",
        "colab_type": "text"
      },
      "source": [
        "#### Checking our available data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Epu-5NgQupdT",
        "colab_type": "code",
        "outputId": "a9315fcf-b520-4789-c6bd-d8dfb4e1d05e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(\"For this experiment, we have available:\\n\")\n",
        "print(str(len(cito_proteins))     + \" Cytosolic proteins;\")\n",
        "print(str(len(secreted_proteins)) + \" Secreted proteins;\")\n",
        "print(str(len(nucleus_proteins))  + \" Nuclear proteins;\" )\n",
        "print(str(len(mito_proteins))     + \" Mitochondrial proteins;\")\n",
        "print(str(len(blind_test))        + \" Blind test proteins;\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For this experiment, we have available:\n",
            "\n",
            "3314 Cytosolic proteins;\n",
            "1605 Secreted proteins;\n",
            "3314 Nuclear proteins;\n",
            "1299 Mitochondrial proteins;\n",
            "20 Blind test proteins;\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIQbYVRDvISa",
        "colab_type": "text"
      },
      "source": [
        "## Preparing different train/dev/test splits for cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eqGuZ8x8PNp",
        "colab_type": "text"
      },
      "source": [
        "Here, we take all  available labeled proteins and split them in equal-sized chunks, where the distribution of the type of proteins is the same across each chunk. The chunk size wil differ for each ratio of splits we inted to use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyC3Ic6v-nzJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "available_data = pd.concat([cito_proteins, secreted_proteins, nucleus_proteins, mito_proteins])\n",
        "available_data = available_data.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp14gHO09xKT",
        "colab_type": "text"
      },
      "source": [
        "#### 60% train, 20% validation, 20% test \n",
        "(k-fold cross-validation with k = 5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGI0yDpN_RUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_splits = []\n",
        "\n",
        "for i in range(5):\n",
        "  train, dev, test = np.split(available_data.sample(frac=1), [int(.6*len(available_data)), int(.8*len(available_data))])\n",
        "  train = train.reset_index(drop=True)\n",
        "  dev   = dev.reset_index(drop=True)\n",
        "  test  = test.reset_index(drop=True)\n",
        "\n",
        "  data_splits.append({\"df\":(train, dev, test)})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uO7mv5dU_JE",
        "colab_type": "text"
      },
      "source": [
        "# Reading and preparing the Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Yu9VpqG-817",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ProteinReader(DatasetReader):\n",
        "  def __init__(self, lazy=False, vocab: Vocabulary=None, token_indexers = None) -> None:\n",
        "    super().__init__(lazy=lazy)\n",
        "    self.reject_probs = None\n",
        "    self._token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer(lowercase_tokens=False)}\n",
        "  \n",
        "  def _read(self, data:pd.DataFrame)->Iterator[Instance]:\n",
        "\n",
        "    for index, row in data.iterrows():\n",
        "      header = row[\"Header\"]\n",
        "      sequence = row[\"Sequence\"]\n",
        "      label = row[\"Label\"]\n",
        "  \n",
        "      yield self.text_to_instance(header, sequence, label)\n",
        "  \n",
        "  def text_to_instance(self, header: str, sequence: str, label)->Instance:\n",
        "    sequence_field = TextField([Token(w) for w in sequence], token_indexers = self._token_indexers)\n",
        "    label_field = LabelField(label)\n",
        "    \n",
        "    \n",
        "    return Instance({\"tokens\": sequence_field, \"label\": label_field})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN_7qyuBwVVj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "e63f7dc4-e983-4e9a-b4fa-2038d4ef939e"
      },
      "source": [
        "reader = ProteinReader()\n",
        "\n",
        "for data_split in data_splits:\n",
        "  train_data = reader.read(data_split[\"df\"][0])\n",
        "  dev_data   = reader.read(data_split[\"df\"][1])\n",
        "  test_data  = reader.read(data_split[\"df\"][2])\n",
        "\n",
        "  data_split[\"inst\"] = (train_data, dev_data, test_data)\n",
        "\n",
        "vocab = Vocabulary.from_instances(train_data + dev_data + test_data)\n",
        "iterator = BucketIterator(batch_size=64, biggest_batch_first=True, sorting_keys=[(\"tokens\", \"num_tokens\")])\n",
        "iterator.index_with(vocab)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5719it [00:06, 862.04it/s] \n",
            "1906it [00:02, 679.58it/s] \n",
            "1907it [00:02, 825.43it/s] \n",
            "5719it [00:06, 853.60it/s] \n",
            "1906it [00:01, 1501.74it/s]\n",
            "1907it [00:03, 563.68it/s]\n",
            "5719it [00:06, 904.39it/s]\n",
            "1906it [00:01, 1497.96it/s]\n",
            "1907it [00:01, 1469.21it/s]\n",
            "5719it [00:06, 818.00it/s] \n",
            "1906it [00:01, 1491.17it/s]\n",
            "1907it [00:05, 369.83it/s]\n",
            "5719it [00:03, 1453.99it/s]\n",
            "1906it [00:01, 1534.92it/s]\n",
            "1907it [00:06, 312.27it/s]\n",
            "100%|██████████| 9532/9532 [00:02<00:00, 3807.05it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-_j-t-5gRKG",
        "colab_type": "text"
      },
      "source": [
        "# Preparing the Predictor class\n",
        "\n",
        "This is the class that will help us get our predictions and metrics, from our trained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duakhtKPgXr5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tonp(tsr): return tsr.detach().cpu().numpy()\n",
        "\n",
        "def get_label(prediction):\n",
        "  return np.argmax(prediction)\n",
        "\n",
        "class Predictor:\n",
        "    def __init__(self, model: Model, iterator,\n",
        "                 cuda_device: int=CUDA_DEVICE) -> None:\n",
        "        self.model = model\n",
        "        self.iterator = iterator\n",
        "        self.cuda_device = cuda_device\n",
        "         \n",
        "    def _extract_data(self, batch) -> np.ndarray:\n",
        "        out_dict = self.model(**batch)\n",
        "        return expit(tonp(out_dict[\"class_logits\"]))\n",
        "     \n",
        "    def predict(self, ds) -> np.ndarray:\n",
        "        pred_generator = self.iterator(ds, num_epochs=1, shuffle=False)\n",
        "        self.model.eval()\n",
        "        pred_generator_tqdm = tqdm(pred_generator,\n",
        "                                   total=self.iterator.get_num_batches(ds))\n",
        "        preds = []\n",
        "        with torch.no_grad():\n",
        "            for batch in pred_generator_tqdm:\n",
        "                batch = nn_util.move_to_device(batch, self.cuda_device)\n",
        "                preds.append(self._extract_data(batch))\n",
        "\n",
        "        return np.concatenate(preds, axis=0)\n",
        "\n",
        "    def update_dataset_with_predictions(self, predictions, data):\n",
        "      predictions = F.softmax(torch.Tensor(predictions), dim = 1).numpy()\n",
        "      labels = np.apply_along_axis(get_label, axis=1, arr=predictions)\n",
        "      confidence = np.apply_along_axis(max, axis = 1, arr = predictions)\n",
        "\n",
        "      res = pd.DataFrame({\"PredictionIndex\": labels, \"Confidence\":confidence})\n",
        "      res[\"Prediction\"] = res[\"PredictionIndex\"].apply(lambda x: vocab.get_token_from_index(x, namespace = 'labels'))\n",
        "      \n",
        "      # data = pd.read_csv(path)\n",
        "      if data.shape[0] == res.shape[0]:\n",
        "        data['Prediction'] = res['Prediction']\n",
        "        data['Confidence'] = res['Confidence']\n",
        "        return data\n",
        "      else:\n",
        "        print(\"\\nShape of predictions and shape of passed dataframe are incompatible\")\n",
        "      return None\n",
        "    \n",
        "    def getConfusionMatrix(self, data):\n",
        "      return pd.crosstab(data['Label'], data['Prediction'])\n",
        "\n",
        "    def getAccuracy(self, data):\n",
        "      return sum((data['Label'] == data[\"Prediction\"]).tolist()) / data.shape[0]\n",
        "\n",
        "    def getMetricsReport(self, data):\n",
        "      return metrics.classification_report(data['Label'], data['Prediction'], digits=3)\n",
        "\n",
        "    def plot_confusion_matrix(self, cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "        \"\"\"\n",
        "        This function prints and plots the confusion matrix.\n",
        "        Normalization can be applied by setting `normalize=True`.\n",
        "        \"\"\" \n",
        "        import itertools\n",
        "        if normalize:\n",
        "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "\n",
        "        plt.figure(figsize=(6,6))\n",
        "        plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "        plt.title(title)\n",
        "        plt.colorbar()\n",
        "        tick_marks = np.arange(len(classes))\n",
        "        plt.xticks(tick_marks, classes, rotation=45)\n",
        "        plt.yticks(tick_marks, classes)\n",
        "\n",
        "        fmt = '.2f' if normalize else 'd'\n",
        "        thresh = cm.max() / 2.\n",
        "        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "            plt.text(j, i, format(cm[i, j], fmt),\n",
        "                    horizontalalignment=\"center\",\n",
        "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "        plt.ylabel('True label')\n",
        "        plt.xlabel('Predicted label')\n",
        "        plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z-7tDPGZScE",
        "colab_type": "text"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwqqNT7UtmYJ",
        "colab_type": "text"
      },
      "source": [
        "During development we ran each of the models bellow on all of the data splits. However, for the sake of brevity, here we train just the first model on all 5 splits and give summarised results, while the rest of the models are trained on just one split (otherwise you are looking at spending a lot of time in this notebook). Simply modify each model's training loop and make it similar to the first one's to train them on all splits as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdz-MS2bCy0y",
        "colab_type": "text"
      },
      "source": [
        "### LSTM Encoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Af79Ow5tZtcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMModel(Model):\n",
        "  def __init__(self, protein_embeddings: TextFieldEmbedder, protein_seq_encoder: Seq2VecEncoder,\n",
        "               out_sz :int=4, vocab: Vocabulary=None):\n",
        "    super().__init__(vocab)\n",
        "    self.protein_embeddings = protein_embeddings\n",
        "    self.protein_seq_encoder = protein_seq_encoder\n",
        "    self.out_sz = out_sz\n",
        "\n",
        "    self.first_projection = nn.Linear(self.protein_seq_encoder.get_output_dim(), int(self.protein_seq_encoder.get_output_dim() /2 ))\n",
        "    self.last_projection = nn.Linear(int(self.protein_seq_encoder.get_output_dim() /2 ), out_sz)\n",
        "\n",
        "    self.loss = nn.BCEWithLogitsLoss()\n",
        "  \n",
        "  # tokens: Dict[str, torch.Tensor], id, label: torch.Tensor\n",
        "  def forward(self, tokens, label) -> torch.Tensor:\n",
        "\n",
        "    mask = get_text_field_mask(tokens)\n",
        "    embeddings = self.protein_embeddings(tokens)\n",
        "\n",
        "    state = self.protein_seq_encoder(embeddings, mask)\n",
        "\n",
        "    state = F.relu(self.first_projection(state))\n",
        "    class_logits = self.last_projection(state)\n",
        "\n",
        "    one_hot_label = F.one_hot(label.long(), self.out_sz).float()\n",
        "\n",
        "    output = {\"class_logits\": class_logits}\n",
        "    output[\"loss\"] = self.loss(class_logits, one_hot_label)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWpftCe7yxqv",
        "colab_type": "text"
      },
      "source": [
        "Training loop for each of the split (again, only this model will be trained all splits, while the rest will be trained on just one split)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtX-yjvFyU9t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM    = 300\n",
        "NUM_EPOCHS    = 20\n",
        "\n",
        "models_per_split = []\n",
        "for data_split in data_splits:\n",
        "  train_data = data_split[\"inst\"][0]\n",
        "  dev_data   = data_split[\"inst\"][1]\n",
        "  test_data  = data_split[\"inst\"][2]\n",
        "\n",
        "  token_embedding = Embedding(num_embeddings=vocab.get_vocab_size(), embedding_dim=EMBEDDING_DIM, padding_index=0)\n",
        "  protein_embeddings: TextFieldEmbedder = BasicTextFieldEmbedder({\"tokens\": token_embedding})\n",
        "\n",
        "  protein_seq_encoder: Seq2VecEncoder = PytorchSeq2VecWrapper(nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, bidirectional=True, num_layers = 1, batch_first=True))\n",
        "\n",
        "  model = LSTMModel(protein_embeddings, protein_seq_encoder).to(device)\n",
        "  CUDA_DEVICE = 0\n",
        "\n",
        "  trainer = Trainer(\n",
        "      model=model,\n",
        "      optimizer=optim.Adam(model.parameters(), lr=0.005),\n",
        "      iterator=iterator,\n",
        "      train_dataset=train_data,\n",
        "      validation_dataset=dev_data,\n",
        "      patience=3,\n",
        "      cuda_device=CUDA_DEVICE,\n",
        "      num_epochs=NUM_EPOCHS,\n",
        "  )\n",
        "\n",
        "  trainer.train()\n",
        "  print(\"\\n\\nModel Trained\\n\")\n",
        "  models_per_split.append(model)\n",
        "\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkFnay4Se83R",
        "colab_type": "text"
      },
      "source": [
        "#### Evaluating Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqoXFP_vgGe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Again, for the sake of brevity, we display the results of the model trained on just the first split\n",
        "# The results for the entire architecture, are the average of the results of the models in the list models_per_split\n",
        "\n",
        "index = 0\n",
        "model = models_per_split[index]\n",
        "train_data = data_splits[index][\"inst\"][0]\n",
        "dev_data   = data_splits[index][\"inst\"][1]\n",
        "test_data  = data_splits[index][\"inst\"][2]\n",
        "\n",
        "seq_iterator = BasicIterator(batch_size=64)\n",
        "seq_iterator.index_with(vocab)\n",
        "predictor = Predictor(model, seq_iterator, cuda_device=CUDA_DEVICE)\n",
        "\n",
        "train_predictions = predictor.predict(train_data)\n",
        "dev_predictions   = predictor.predict(dev_data)\n",
        "test_predictions  = predictor.predict(test_data)\n",
        "\n",
        "updated_train_data = predictor.update_dataset_with_predictions(train_predictions, df_train_data)\n",
        "updated_dev_data   = predictor.update_dataset_with_predictions(dev_predictions, df_dev_data)\n",
        "updated_test_data  = predictor.update_dataset_with_predictions(test_predictions, df_test_data)\n",
        "\n",
        "print(\"\\n\\nTrain Accuracy: \" + str(predictor.getAccuracy(updated_train_data)))\n",
        "print(\"Dev Accuracy: \"     + str(predictor.getAccuracy(updated_dev_data)))\n",
        "print(\"Test Accuracy: \"    + str(predictor.getAccuracy(updated_test_data)))\n",
        "\n",
        "print(\"\\nGorodkin Coeff. - Train: \" + str(matthews_corrcoef(updated_train_data['Label'], updated_train_data['Prediction'])))\n",
        "print(\"Gorodkin Coeff. - Dev: \"   + str(matthews_corrcoef(updated_dev_data['Label'], updated_dev_data['Prediction'])))\n",
        "print(\"Gorodkin Coeff. - Test: \"  + str(matthews_corrcoef(updated_test_data['Label'], updated_test_data['Prediction'])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7hgE6AUNkp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Metrics Report:\\n\")\n",
        "print(predictor.getMetricsReport(updated_test_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfplQ7cG_Vjq",
        "colab_type": "text"
      },
      "source": [
        "### CNN Encoder Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQS19pVDDZLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNNModel(Model):\n",
        "  def __init__(self, protein_embeddings: TextFieldEmbedder, protein_seq_encoder: Seq2VecEncoder,\n",
        "               out_sz :int=4, vocab: Vocabulary=None):\n",
        "    super().__init__(vocab)\n",
        "    self.protein_embeddings = protein_embeddings\n",
        "    self.protein_seq_encoder = protein_seq_encoder\n",
        "    self.out_sz = out_sz\n",
        "    self.projection = nn.Linear(self.protein_seq_encoder.get_output_dim(), out_sz)\n",
        "    self.loss = nn.BCEWithLogitsLoss()\n",
        "  \n",
        "  # tokens: Dict[str, torch.Tensor], id, label: torch.Tensor\n",
        "  def forward(self, tokens, label) -> torch.Tensor:\n",
        "\n",
        "    mask = get_text_field_mask(tokens)\n",
        "    embeddings = self.protein_embeddings(tokens)\n",
        "    state = self.protein_seq_encoder(embeddings, mask)\n",
        "\n",
        "    class_logits = self.projection(state)\n",
        "    one_hot_label = F.one_hot(label.long(), self.out_sz).float()\n",
        "\n",
        "    output = {\"class_logits\": class_logits}\n",
        "    output[\"loss\"] = self.loss(class_logits, one_hot_label)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85wcLfSv_Y-q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = data_splits[0][\"inst\"][0]\n",
        "dev_data   = data_splits[0][\"inst\"][1]\n",
        "test_data  = data_splits[0][\"inst\"][2]\n",
        "\n",
        "df_train_data = data_splits[0][\"df\"][0]\n",
        "df_dev_data   = data_splits[0][\"df\"][1]\n",
        "df_test_data  = data_splits[0][\"df\"][2]\n",
        "\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM    = 300\n",
        "NUM_EPOCHS    = 30\n",
        "\n",
        "token_embedding = Embedding(num_embeddings=vocab.get_vocab_size(), embedding_dim=EMBEDDING_DIM, padding_index=0)\n",
        "protein_embeddings: TextFieldEmbedder = BasicTextFieldEmbedder({\"tokens\": token_embedding})\n",
        "\n",
        "protein_seq_encoder = CnnEncoder(embedding_dim=EMBEDDING_DIM, num_filters=300, ngram_filter_sizes = (2, 3, 4, 5)) \n",
        "\n",
        "model = CNNModel(protein_embeddings, protein_seq_encoder).to(device)\n",
        "CUDA_DEVICE = 0\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optim.Adam(model.parameters(), lr=0.001),\n",
        "    iterator=iterator,\n",
        "    train_dataset=train_data,\n",
        "    validation_dataset=dev_data,\n",
        "    patience=2,\n",
        "    cuda_device=CUDA_DEVICE,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFU-4V44gAsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_iterator = BasicIterator(batch_size=64)\n",
        "seq_iterator.index_with(vocab)\n",
        "predictor = Predictor(model, seq_iterator, cuda_device=CUDA_DEVICE)\n",
        "\n",
        "train_predictions = predictor.predict(train_data)\n",
        "dev_predictions   = predictor.predict(dev_data)\n",
        "test_predictions  = predictor.predict(test_data)\n",
        "\n",
        "updated_train_data = predictor.update_dataset_with_predictions(train_predictions, df_train_data)\n",
        "updated_dev_data   = predictor.update_dataset_with_predictions(dev_predictions, df_dev_data)\n",
        "updated_test_data  = predictor.update_dataset_with_predictions(test_predictions, df_test_data)\n",
        "\n",
        "print(\"\\n\\nTrain Accuracy: \" + str(predictor.getAccuracy(updated_train_data)))\n",
        "print(\"Dev Accuracy: \"     + str(predictor.getAccuracy(updated_dev_data)))\n",
        "print(\"Test Accuracy: \"    + str(predictor.getAccuracy(updated_test_data)))\n",
        "\n",
        "print(\"\\nGorodkin Coeff. - Train: \" + str(matthews_corrcoef(updated_train_data['Label'], updated_train_data['Prediction'])))\n",
        "print(\"Gorodkin Coeff. - Dev: \"   + str(matthews_corrcoef(updated_dev_data['Label'], updated_dev_data['Prediction'])))\n",
        "print(\"Gorodkin Coeff. - Test: \"  + str(matthews_corrcoef(updated_test_data['Label'], updated_test_data['Prediction'])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqdHeMjJ0Kdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Metrics Report:\\n\")\n",
        "print(predictor.getMetricsReport(updated_test_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1Izp0cGbL22",
        "colab_type": "text"
      },
      "source": [
        "### CNN - LSTM Hybrid 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRpvOkiRJevD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM_CNN_Model(Model):\n",
        "  def __init__(self, protein_embeddings: TextFieldEmbedder, protein_LSTM_encoder: Seq2SeqEncoder, \n",
        "               protein_CNN_encoder: Seq2VecEncoder, out_sz :int=4, vocab: Vocabulary=None):\n",
        "    super().__init__(vocab)\n",
        "    self.protein_embeddings = protein_embeddings\n",
        "    self.protein_LSTM_encoder = protein_LSTM_encoder\n",
        "    self.protein_CNN_encoder = protein_CNN_encoder\n",
        "    self.out_sz = out_sz\n",
        "\n",
        "    self.first_projection = nn.Linear(self.protein_CNN_encoder.get_output_dim(), int(self.protein_CNN_encoder.get_output_dim() /2 ))\n",
        "    self.last_projection = nn.Linear(int(self.protein_CNN_encoder.get_output_dim() /2 ), out_sz)\n",
        "\n",
        "    self.loss = nn.BCEWithLogitsLoss()\n",
        "  \n",
        "  # tokens: Dict[str, torch.Tensor], id, label: torch.Tensor\n",
        "  def forward(self, tokens, label) -> torch.Tensor:\n",
        "\n",
        "    mask = get_text_field_mask(tokens)\n",
        "    embeddings = self.protein_embeddings(tokens)\n",
        "    \n",
        "    lstm_encodings = self.protein_LSTM_encoder(embeddings, mask)\n",
        "    lstm_mask = get_text_field_mask({\"tokens\":lstm_encodings})\n",
        "    \n",
        "    state = self.protein_CNN_encoder(lstm_encodings, lstm_mask)\n",
        "\n",
        "    state = F.relu(self.first_projection(state))\n",
        "    class_logits = self.last_projection(state)\n",
        "    \n",
        "    one_hot_label = F.one_hot(label.long(), self.out_sz).float()\n",
        "\n",
        "    output = {\"class_logits\": class_logits}\n",
        "    output[\"loss\"] = self.loss(class_logits, one_hot_label)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36YQXS8AJrS7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "outputId": "f1e71a71-acf2-4afb-e23b-d086d0997809"
      },
      "source": [
        "train_data = data_splits[0][\"inst\"][0]\n",
        "dev_data   = data_splits[0][\"inst\"][1]\n",
        "test_data  = data_splits[0][\"inst\"][2]\n",
        "\n",
        "df_train_data = data_splits[0][\"df\"][0]\n",
        "df_dev_data   = data_splits[0][\"df\"][1]\n",
        "df_test_data  = data_splits[0][\"df\"][2]\n",
        "\n",
        "EMBEDDING_DIM = 256\n",
        "HIDDEN_DIM    = 256\n",
        "NUM_EPOCHS    = 30\n",
        "\n",
        "token_embedding = Embedding(num_embeddings=vocab.get_vocab_size(), embedding_dim=EMBEDDING_DIM, padding_index=0)\n",
        "protein_embeddings: TextFieldEmbedder = BasicTextFieldEmbedder({\"tokens\": token_embedding})\n",
        "\n",
        "protein_LSTM_encoder = PytorchSeq2SeqWrapper(nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, bidirectional=True, batch_first=True))\n",
        "protein_CNN_encoder = CnnEncoder(embedding_dim=protein_LSTM_encoder.get_output_dim(), num_filters=300, ngram_filter_sizes = (2, 3, 4, 5))\n",
        "\n",
        "\n",
        "model = LSTM_CNN_Model(protein_embeddings, protein_LSTM_encoder, protein_CNN_encoder).to(device)\n",
        "CUDA_DEVICE = 0\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optim.Adam(model.parameters(), lr=0.002),\n",
        "    iterator=iterator,\n",
        "    train_dataset=train_data,\n",
        "    validation_dataset=dev_data,\n",
        "    patience=3,\n",
        "    cuda_device=CUDA_DEVICE,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "gc.collect()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.5306 ||: 100%|██████████| 90/90 [00:26<00:00,  3.35it/s]\n",
            "loss: 0.5036 ||: 100%|██████████| 30/30 [00:03<00:00,  7.53it/s]\n",
            "loss: 0.5163 ||: 100%|██████████| 90/90 [00:24<00:00,  3.73it/s]\n",
            "loss: 0.4756 ||: 100%|██████████| 30/30 [00:03<00:00,  9.77it/s]\n",
            "loss: 0.4744 ||: 100%|██████████| 90/90 [00:24<00:00,  3.73it/s]\n",
            "loss: 0.4385 ||: 100%|██████████| 30/30 [00:03<00:00,  9.50it/s]\n",
            "loss: 0.4046 ||: 100%|██████████| 90/90 [00:24<00:00,  3.72it/s]\n",
            "loss: 0.3878 ||: 100%|██████████| 30/30 [00:03<00:00,  9.62it/s]\n",
            "loss: 0.3521 ||: 100%|██████████| 90/90 [00:24<00:00,  3.73it/s]\n",
            "loss: 0.3744 ||: 100%|██████████| 30/30 [00:03<00:00,  9.55it/s]\n",
            "loss: 0.3302 ||: 100%|██████████| 90/90 [00:24<00:00,  3.72it/s]\n",
            "loss: 0.3575 ||: 100%|██████████| 30/30 [00:03<00:00,  9.48it/s]\n",
            "loss: 0.3219 ||: 100%|██████████| 90/90 [00:24<00:00,  3.72it/s]\n",
            "loss: 0.3352 ||: 100%|██████████| 30/30 [00:03<00:00,  9.72it/s]\n",
            "loss: 0.3113 ||: 100%|██████████| 90/90 [00:24<00:00,  3.71it/s]\n",
            "loss: 0.3441 ||: 100%|██████████| 30/30 [00:03<00:00,  9.46it/s]\n",
            "loss: 0.2978 ||: 100%|██████████| 90/90 [00:24<00:00,  3.70it/s]\n",
            "loss: 0.3458 ||: 100%|██████████| 30/30 [00:03<00:00,  9.53it/s]\n",
            "loss: 0.2994 ||: 100%|██████████| 90/90 [00:24<00:00,  3.74it/s]\n",
            "loss: 0.3317 ||: 100%|██████████| 30/30 [00:03<00:00,  9.52it/s]\n",
            "loss: 0.2830 ||: 100%|██████████| 90/90 [00:24<00:00,  3.72it/s]\n",
            "loss: 0.3246 ||: 100%|██████████| 30/30 [00:03<00:00,  9.56it/s]\n",
            "  0%|          | 0/90 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-a54933c6e7fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/allennlp/training/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_counter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m             \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m             \u001b[0;31m# get peak of memory usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/allennlp/training/trainer.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nan loss encountered\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFcQmrNNKDIR",
        "colab_type": "code",
        "outputId": "70784fe5-005f-4f34-cf1d-fdb5888573d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "seq_iterator = BasicIterator(batch_size=64)\n",
        "seq_iterator.index_with(vocab)\n",
        "predictor = Predictor(model, seq_iterator, cuda_device=CUDA_DEVICE)\n",
        "\n",
        "train_predictions = predictor.predict(train_data)\n",
        "dev_predictions   = predictor.predict(dev_data)\n",
        "test_predictions  = predictor.predict(test_data)\n",
        "\n",
        "updated_train_data = predictor.update_dataset_with_predictions(train_predictions, df_train_data)\n",
        "updated_dev_data   = predictor.update_dataset_with_predictions(dev_predictions, df_dev_data)\n",
        "updated_test_data  = predictor.update_dataset_with_predictions(test_predictions, df_test_data)\n",
        "\n",
        "print(\"\\n\\nTrain Accuracy: \" + str(predictor.getAccuracy(updated_train_data)))\n",
        "print(\"Dev Accuracy: \"     + str(predictor.getAccuracy(updated_dev_data)))\n",
        "print(\"Test Accuracy: \"    + str(predictor.getAccuracy(updated_test_data)))\n",
        "\n",
        "print(\"\\nGorodkin Coeff. - Train: \" + str(matthews_corrcoef(updated_train_data['Label'], updated_train_data['Prediction'])))\n",
        "print(\"Gorodkin Coeff. - Dev: \"   + str(matthews_corrcoef(updated_dev_data['Label'], updated_dev_data['Prediction'])))\n",
        "print(\"Gorodkin Coeff. - Test: \"  + str(matthews_corrcoef(updated_test_data['Label'], updated_test_data['Prediction'])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 90/90 [00:23<00:00,  3.89it/s]\n",
            "100%|██████████| 30/30 [00:07<00:00,  3.93it/s]\n",
            "100%|██████████| 30/30 [00:08<00:00,  3.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Train Accuracy: 0.642594859241126\n",
            "Dev Accuracy: 0.602308499475341\n",
            "Test Accuracy: 0.5920293654955427\n",
            "\n",
            "Gorodkin Coeff. - Train: 0.6150793531578164\n",
            "Gorodkin Coeff. - Dev: 0.5434327005649392\n",
            "Gorodkin Coeff. - Test: 0.5409657716823505\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWfcmAlt3ExS",
        "colab_type": "code",
        "outputId": "dedbb261-fbb9-44ae-a564-ddd19166dbde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(\"Metrics Report:\\n\")\n",
        "print(predictor.getMetricsReport(updated_test_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Metrics Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        cito      0.475     0.952     0.634       681\n",
            "        mito      0.860     0.717     0.782       240\n",
            "     nucleus      0.243     0.013     0.025       671\n",
            "    secreted      0.954     0.930     0.942       315\n",
            "\n",
            "    accuracy                          0.588      1907\n",
            "   macro avg      0.633     0.653     0.596      1907\n",
            "weighted avg      0.521     0.588     0.489      1907\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjK2Q9qiJp2i",
        "colab_type": "code",
        "outputId": "29453bd0-e482-4f9d-8e97-0c07f6c3c671",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(updated_test_data['Label'], updated_test_data['Prediction'], labels =  ['cito', 'mito', 'nucleus', 'secreted'] )\n",
        "predictor.plot_confusion_matrix(cm, ['cito', 'mito', 'nucleus', 'secreted'], \n",
        "                                normalize=True, title = 'Confusion matrix')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAGRCAYAAABVKtXaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH2Z4gP2qishBAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YLgHnRz7EIZ",
        "colab_type": "text"
      },
      "source": [
        "### CNN - LSTM Hybrid 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtJPEGYd7IH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN_LSTM_Model(Model):\n",
        "  def __init__(self, protein_embeddings: TextFieldEmbedder, cnn_encoder: nn.Conv2d, protein_LSTM_encoder: Seq2VecEncoder, \n",
        "               out_sz :int=4, vocab: Vocabulary=None):\n",
        "    super().__init__(vocab)\n",
        "    self.protein_embeddings = protein_embeddings\n",
        "    self.cnn_encoder = cnn_encoder\n",
        "\n",
        "    self.protein_LSTM_encoder = protein_LSTM_encoder\n",
        "    self.out_sz = out_sz\n",
        "\n",
        "    self.first_projection = nn.Linear(self.protein_LSTM_encoder.get_output_dim(), int(self.protein_LSTM_encoder.get_output_dim() /2 ))\n",
        "    self.last_projection = nn.Linear(int(self.protein_LSTM_encoder.get_output_dim() /2 ), out_sz)\n",
        "\n",
        "    self.loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "  def get_mask_from_batch(self, x):\n",
        "    ret = ()\n",
        "    for instance in x:\n",
        "      instance = instance.clone().detach().cpu().numpy()\n",
        "      ret = ret + (self.get_mask(instance),)\n",
        "  \n",
        "    return torch.stack(ret)\n",
        "\n",
        "  def get_mask(self, instance):\n",
        "    mask = np.logical_not((instance[1:] == instance[:-1]).all(axis = 1))\n",
        "    mask = torch.Tensor(mask)\n",
        "\n",
        "    if mask[-1] and not sum(instance[-1] == instance[-2]):\n",
        "      mask = torch.cat((mask.int(), torch.tensor([1], dtype = torch.int32))).long()\n",
        "    else:\n",
        "      mask = torch.cat((mask.int(), torch.tensor([0], dtype = torch.int32))).long()\n",
        "    return mask\n",
        "  \n",
        "  # tokens: Dict[str, torch.Tensor], id, label: torch.Tensor\n",
        "  def forward(self, tokens, label) -> torch.Tensor:\n",
        "\n",
        "    mask = get_text_field_mask(tokens)\n",
        "    embeddings = self.protein_embeddings(tokens)\n",
        "    embeddings.unsqueeze_(dim = 1)\n",
        "\n",
        "    cnn_encoded_proteins = self.cnn_encoder(embeddings)\n",
        "    cnn_encoded_proteins = cnn_encoded_proteins.squeeze().transpose(1,2)\n",
        "    cnn_encoded_proteins_mask = self.get_mask_from_batch(cnn_encoded_proteins).to(device)\n",
        "    \n",
        "    state = self.protein_LSTM_encoder(cnn_encoded_proteins, cnn_encoded_proteins_mask)\n",
        "    state = F.relu(self.first_projection(state))\n",
        "\n",
        "    class_logits = self.last_projection(state)\n",
        "    \n",
        "    one_hot_label = F.one_hot(label.long(), self.out_sz).float()\n",
        "\n",
        "    output = {\"class_logits\": class_logits}\n",
        "    output[\"loss\"] = self.loss(class_logits, one_hot_label)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X_pxsq67IQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = data_splits[0][\"inst\"][0]\n",
        "dev_data   = data_splits[0][\"inst\"][1]\n",
        "test_data  = data_splits[0][\"inst\"][2]\n",
        "\n",
        "df_train_data = data_splits[0][\"df\"][0]\n",
        "df_dev_data   = data_splits[0][\"df\"][1]\n",
        "df_test_data  = data_splits[0][\"df\"][2]\n",
        "\n",
        "EMBEDDING_DIM            = 300\n",
        "HIDDEN_DIM               = 300\n",
        "CONVOLUTED_EMBEDDING_DIM = 300\n",
        "NUM_EPOCHS               = 30\n",
        "\n",
        "token_embedding = Embedding(num_embeddings=vocab.get_vocab_size(), embedding_dim=EMBEDDING_DIM, padding_index=0)\n",
        "protein_embeddings: TextFieldEmbedder = BasicTextFieldEmbedder({\"tokens\": token_embedding})\n",
        "\n",
        "cnn_encoder = Conv2d(in_channels=1, out_channels=CONVOLUTED_EMBEDDING_DIM, kernel_size=(4, EMBEDDING_DIM), stride = (4,1), padding=(0,0))\n",
        "protein_LSTM_encoder: Seq2VecEncoder = PytorchSeq2VecWrapper(nn.LSTM(CONVOLUTED_EMBEDDING_DIM, HIDDEN_DIM, bidirectional=True, batch_first=True))\n",
        "\n",
        "model = CNN_LSTM_Model(protein_embeddings, cnn_encoder, protein_LSTM_encoder).to(device)\n",
        "CUDA_DEVICE = 0\n",
        "\n",
        "print(\"Here\")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optim.Adam(model.parameters(), lr=0.0005),\n",
        "    iterator=iterator,\n",
        "    train_dataset=train_data,\n",
        "    validation_dataset=dev_data,\n",
        "    patience=2,\n",
        "    cuda_device=CUDA_DEVICE,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrV9w-fe7IgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_iterator = BasicIterator(batch_size=64)\n",
        "seq_iterator.index_with(vocab)\n",
        "predictor = Predictor(model, seq_iterator, cuda_device=CUDA_DEVICE)\n",
        "\n",
        "train_predictions = predictor.predict(train_data)\n",
        "dev_predictions   = predictor.predict(dev_data)\n",
        "test_predictions  = predictor.predict(test_data)\n",
        "\n",
        "updated_train_data = predictor.update_dataset_with_predictions(train_predictions, df_train_data)\n",
        "updated_dev_data   = predictor.update_dataset_with_predictions(dev_predictions, df_dev_data)\n",
        "updated_test_data  = predictor.update_dataset_with_predictions(test_predictions, df_test_data)\n",
        "\n",
        "print(\"\\n\\nTrain Accuracy: \" + str(predictor.getAccuracy(updated_train_data)))\n",
        "print(\"Dev Accuracy: \"     + str(predictor.getAccuracy(updated_dev_data)))\n",
        "print(\"Test Accuracy: \"    + str(predictor.getAccuracy(updated_test_data)))\n",
        "\n",
        "print(\"\\nGorodkin Coeff. - Train: \" + str(matthews_corrcoef(updated_train_data['Label'], updated_train_data['Prediction'])))\n",
        "print(\"Gorodkin Coeff. - Dev: \"   + str(matthews_corrcoef(updated_dev_data['Label'], updated_dev_data['Prediction'])))\n",
        "print(\"Gorodkin Coeff. - Test: \"  + str(matthews_corrcoef(updated_test_data['Label'], updated_test_data['Prediction'])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Sl8Y9-i61Rz",
        "colab_type": "code",
        "outputId": "2311919c-2d66-42e6-bd60-d45da5235461",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print(\"Metrics Report:\\n\")\n",
        "print(predictor.getMetricsReport(updated_test_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Metrics Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        cito      0.405     0.361     0.382       681\n",
            "        mito      0.837     0.725     0.777       240\n",
            "     nucleus      0.433     0.480     0.455       671\n",
            "    secreted      0.868     0.959     0.911       315\n",
            "\n",
            "    accuracy                          0.547      1907\n",
            "   macro avg      0.636     0.631     0.631      1907\n",
            "weighted avg      0.546     0.547     0.545      1907\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqT25ujYI056",
        "colab_type": "text"
      },
      "source": [
        "# Blind Test Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OHyz_LXI6KS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "outputId": "cece2dc3-2aa3-4d3f-e354-07089bf183d1"
      },
      "source": [
        "seq_iterator = BasicIterator(batch_size=64)\n",
        "seq_iterator.index_with(vocab)\n",
        "predictor = Predictor(model, seq_iterator, cuda_device=CUDA_DEVICE)\n",
        "\n",
        "reader = ProteinReader()\n",
        "blind_test_data = reader.read(blind_test)\n",
        "blind_test_predictions =  predictor.predict(blind_test_data)\n",
        "blind_test_predictions = predictor.update_dataset_with_predictions(blind_test_predictions, blind_test)\n",
        "\n",
        "del blind_test_predictions[\"Label\"] # see comment in cell where the blind_test file is processed\n",
        "blind_test_predictions[[\"Header\", \"Prediction\", \"Confidence\"]]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "20it [00:00, 940.80it/s]\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100%|██████████| 1/1 [00:00<00:00,  8.30it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Header</th>\n",
              "      <th>Prediction</th>\n",
              "      <th>Confidence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SEQ677</td>\n",
              "      <td>secreted</td>\n",
              "      <td>0.467377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SEQ231</td>\n",
              "      <td>secreted</td>\n",
              "      <td>0.445681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SEQ871</td>\n",
              "      <td>secreted</td>\n",
              "      <td>0.472120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SEQ388</td>\n",
              "      <td>secreted</td>\n",
              "      <td>0.373054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SEQ122</td>\n",
              "      <td>nucleus</td>\n",
              "      <td>0.308769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SEQ758</td>\n",
              "      <td>nucleus</td>\n",
              "      <td>0.323403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SEQ333</td>\n",
              "      <td>mito</td>\n",
              "      <td>0.284239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>SEQ937</td>\n",
              "      <td>nucleus</td>\n",
              "      <td>0.284580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>SEQ351</td>\n",
              "      <td>mito</td>\n",
              "      <td>0.335036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SEQ202</td>\n",
              "      <td>mito</td>\n",
              "      <td>0.380241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>SEQ608</td>\n",
              "      <td>mito</td>\n",
              "      <td>0.334629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>SEQ402</td>\n",
              "      <td>cito</td>\n",
              "      <td>0.302578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>SEQ433</td>\n",
              "      <td>secreted</td>\n",
              "      <td>0.365934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>SEQ821</td>\n",
              "      <td>secreted</td>\n",
              "      <td>0.467991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>SEQ322</td>\n",
              "      <td>nucleus</td>\n",
              "      <td>0.320344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>SEQ982</td>\n",
              "      <td>nucleus</td>\n",
              "      <td>0.323842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>SEQ951</td>\n",
              "      <td>mito</td>\n",
              "      <td>0.268168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>SEQ173</td>\n",
              "      <td>nucleus</td>\n",
              "      <td>0.308427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>SEQ862</td>\n",
              "      <td>nucleus</td>\n",
              "      <td>0.310905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>SEQ224</td>\n",
              "      <td>mito</td>\n",
              "      <td>0.297887</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Header Prediction  Confidence\n",
              "0   SEQ677   secreted    0.467377\n",
              "1   SEQ231   secreted    0.445681\n",
              "2   SEQ871   secreted    0.472120\n",
              "3   SEQ388   secreted    0.373054\n",
              "4   SEQ122    nucleus    0.308769\n",
              "5   SEQ758    nucleus    0.323403\n",
              "6   SEQ333       mito    0.284239\n",
              "7   SEQ937    nucleus    0.284580\n",
              "8   SEQ351       mito    0.335036\n",
              "9   SEQ202       mito    0.380241\n",
              "10  SEQ608       mito    0.334629\n",
              "11  SEQ402       cito    0.302578\n",
              "12  SEQ433   secreted    0.365934\n",
              "13  SEQ821   secreted    0.467991\n",
              "14  SEQ322    nucleus    0.320344\n",
              "15  SEQ982    nucleus    0.323842\n",
              "16  SEQ951       mito    0.268168\n",
              "17  SEQ173    nucleus    0.308427\n",
              "18  SEQ862    nucleus    0.310905\n",
              "19  SEQ224       mito    0.297887"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}